{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from time import time\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "# from spacy import displacy # see if we need that\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(style='seaborn')\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "col_list = ['text', 'class']\n",
    "df_full = pd.read_csv('data/data_set.csv', usecols=col_list)\n",
    "df = df_full[['text']]\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df_full.head()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower casing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"text_lower\"] = df[\"text\"].str.lower()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation removal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION_TO_REMOVE = '–«!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~»●·’“”'\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCTUATION_TO_REMOVE))\n",
    "\n",
    "\n",
    "df[\"text_wo_punct\"] = df[\"text_lower\"].apply(\n",
    "    lambda text: remove_punctuation(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords removal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_lower = list(map(lambda x: x.lower(), stopwords.words('greek')))\n",
    "\n",
    "STOPWORDS_GREEK = set(stopwords_lower)\n",
    "\n",
    "# text_tokens = word_tokenize(text) use nltk tokenization\n",
    "\n",
    "\n",
    "def import_additional_greek_stopwords(STOPWORDS_GREEK):\n",
    "\n",
    "    additional_stopwords = open('additional_stopwords.txt', 'r')\n",
    "    for line in additional_stopwords:\n",
    "        words = line.strip()\n",
    "        STOPWORDS_GREEK.add(words)\n",
    "    return STOPWORDS_GREEK\n",
    "\n",
    "\n",
    "STOPWORDS_GREEK = import_additional_greek_stopwords(STOPWORDS_GREEK)\n",
    "# print(STOPWORDS_GREEK)\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if not word in STOPWORDS_GREEK])\n",
    "\n",
    "\n",
    "df[\"text_wo_stop\"] = df[\"text_wo_punct\"].apply(\n",
    "    lambda text: remove_stopwords(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the columns which are no longer needed\n",
    "df.drop([\"text_lower\", \"text_wo_punct\"], axis=1, inplace=True)\n",
    "\n",
    "nlp = spacy.load(\"el_core_news_sm\")\n",
    "# nlp.remove_pipe(\"tagger\")\n",
    "\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    \"\"\"custom function to lemmatize text\"\"\"\n",
    "    doc = nlp(text)\n",
    "    # pos_tagged_text = text.pos\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "\n",
    "df[\"text_lemmatized\"] = df[\"text_wo_stop\"].apply(\n",
    "    lambda text: lemmatize_words(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intonation removal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_intonation(text):\n",
    "\n",
    "    rep = {\"ά\": \"α\", \"έ\": \"ε\", \"ή\": \"η\", \"ί\": \"ι\", \"ό\": \"ο\", \"ύ\": \"υ\", \"ώ\": \"ω\", \"ϊ\": \"ι\",\n",
    "           \"ἀ\": \"α\", \"ἐ\": \"ε\", \"ἤ\": \"η\", \"ἰ\": \"ι\", \"ἄ\": \"α\", \"ὐ\": \"υ\", \"ὡ\": \"ω\", \"ὦ\": \"ω\",\n",
    "           'ὖ': 'υ', 'ὅ': 'ο', 'ῆ': 'η', 'ῇ': 'η', 'ῦ': 'υ', 'ὁ': 'ο', 'ὑ': 'υ', 'ὲ': 'ε',\n",
    "           'ὺ': 'υ', 'ἂ': 'α', 'ἵ': 'ι', 'ὴ': 'η', 'ὰ': 'α', 'ἅ': 'α', 'ὶ': 'ι', 'ἴ': 'ι',\n",
    "           'ὸ': 'ο', 'ἥ': 'η', 'ἡ': 'η', 'ὕ': 'υ', 'ἔ': 'ε', 'ἳ': 'ι', 'ὗ': 'υ', 'ἃ': 'α',\n",
    "           'ὃ': 'ο', 'ὥ': 'ω', 'ὔ': 'υ', 'ῖ': 'ι', 'ἣ': 'η', 'ἷ': 'ι', 'ἑ': 'ε', 'ᾧ': 'ω',\n",
    "           'ἢ': 'η', 'ΐ': 'ι', }\n",
    "\n",
    "    rep = dict((nltk.re.escape(k), v) for k, v in rep.items())\n",
    "    pattern = nltk.re.compile(\"|\".join(rep.keys()))\n",
    "    text = pattern.sub(lambda m: rep[nltk.re.escape(m.group(0))], text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"text_wo_intonation\"] = df[\"text_lemmatized\"].apply(\n",
    "    lambda text: remove_intonation(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1000 most rare words removal:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect words:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter()\n",
    "for text in df[\"text_wo_intonation\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "\n",
    "# show ten least frequent elements:\n",
    "cnt.most_common()[:-1000-1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the two columns which are no longer needed\n",
    "# df.drop([\"text_lemmatized\", \"text_wo_stop\", \"text\"], axis=1, inplace=True)\n",
    "\n",
    "n_rare_words = 1000\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "\n",
    "\n",
    "def remove_rarewords(text):\n",
    "    \"\"\"custom function to remove rare words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "\n",
    "\n",
    "df[\"text_wo_rare\"] = df[\"text_wo_intonation\"].apply(\n",
    "    lambda text: remove_rarewords(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers removal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns which are no longer needed\n",
    "# df.drop([\"text_wo_freq\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def drop_numbers(text):\n",
    "    text_wo_numbers = re.sub(r'[0-9]+', '', text)\n",
    "    return text_wo_numbers\n",
    "\n",
    "\n",
    "df[\"text_wo_numbers\"] = df[\"text_wo_intonation\"].apply(\n",
    "    lambda text: drop_numbers(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single letter words removal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_single_letter_words(text):\n",
    "    return ' '.join([w for w in text.split() if len(w) > 1])\n",
    "\n",
    "\n",
    "df[\"text_wo_single_letters\"] = df[\"text_wo_numbers\"].apply(\n",
    "    lambda text: drop_single_letter_words(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of s in the end of every word ('ς'):\n",
    "\n",
    "This section, as with intonation, is a particularity of the greek language. It attempts to immitate lemmatization and stemming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_TO_REMOVE = 'ς'\n",
    "\n",
    "\n",
    "def remove_final_s(text):\n",
    "    return re.sub('ς', '', text)\n",
    "\n",
    "\n",
    "df[\"text_wo_final_s\"] = df[\"text_wo_single_letters\"].apply(\n",
    "    lambda text: remove_final_s(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add labels to the pre-processed df:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns which are no longer needed , \"text_lemmatized\"\n",
    "df.drop([\"text_wo_single_letters\", \"text_wo_intonation\", \"text_lemmatized\", \"text_wo_stop\", \"text\",\n",
    "        \"text_wo_numbers\", \"text_wo_rare\"], axis=1, inplace=True)\n",
    "\n",
    "# Set up data set with preprocessed text & classes:\n",
    "df['label'] = df_full['class']\n",
    "df.columns = ['text', 'label']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_distribution = (df['label'].value_counts() * 100) / len(df)\n",
    "\n",
    "# Add value labels\n",
    "\n",
    "\n",
    "def add_labels(x, y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i], \"%.2f\" % round(y[i], 2) + \"%\", ha='center')\n",
    "\n",
    "\n",
    "plt.bar(label_distribution.index, label_distribution)\n",
    "add_labels(label_distribution.index, label_distribution)\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()\n",
    "\n",
    "# See missing values:\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data set to train, validate and test:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_test = model_selection.train_test_split(df, test_size=0.2, random_state=25)\n",
    "\n",
    "# Split to train validate and test\n",
    "df_train, df_validate, df_test = np.split(df.sample(frac=1, random_state=42), [\n",
    "                                          int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "# print(f\"No. of training examples: {df_train.shape[0]}\")\n",
    "# print(f\"No. of testing examples: {df_test.shape[0]}\")\n",
    "# print(f\"No. of validating examples: {df_validate.shape[0]}\")\n",
    "\n",
    "# Get X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train = df_train['text']\n",
    "y_train = df_train['label']\n",
    "\n",
    "X_val = df_validate['text']\n",
    "y_val = df_validate['label']\n",
    "\n",
    "X_test = df_test['text']\n",
    "y_test = df_test['label']\n",
    "\n",
    "print(\"Train set has total {0} entries with {1:.2f}% belonging to class \\'Γυναικοκτονία' and {2:.2f}% to class \\'Ανθρωποκτονία'.\".format(len(X_train),\n",
    "                                                                                                                                         (len(\n",
    "                                                                                                                                             X_train[y_train == 'Γυναικοκτονία']) / (len(X_train)*1.))*100,\n",
    "                                                                                                                                         (len(X_train[y_train == 'Ανθρωποκτονία']) / (len(X_train)*1.))*100))\n",
    "print(\"Validation set has total {0} entries with {1:.2f}% belonging to class \\'Γυναικοκτονία' and {2:.2f}% to class \\'Ανθρωποκτονία'.\".format(len(X_val),\n",
    "                                                                                                                                              (len(\n",
    "                                                                                                                                                  X_val[y_val == 'Γυναικοκτονία']) / (len(X_val)*1.))*100,\n",
    "                                                                                                                                              (len(X_val[y_val == 'Ανθρωποκτονία']) / (len(X_val)*1.))*100))\n",
    "print(\"Test set has total {0} entries with {1:.2f}% belonging to class \\'Γυναικοκτονία' and {2:.2f}% to class \\'Ανθρωποκτονία'.\".format(len(X_test),\n",
    "                                                                                                                                        (len(\n",
    "                                                                                                                                            X_test[y_test == 'Γυναικοκτονία']) / (len(X_test)*1.))*100,\n",
    "                                                                                                                                        (len(X_test[y_test == 'Ανθρωποκτονία']) / (len(X_test)*1.))*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_summary(pipeline, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"custom function to calculate accuracy for models\"\"\"\n",
    "    if len(X_test[y_test == 0]) / (len(X_test)*1.) > 0.5:\n",
    "        null_accuracy = len(X_test[y_test == 0]) / (len(X_test)*1.)\n",
    "    else:\n",
    "        null_accuracy = 1. - (len(X_test[y_test == 0]) / (len(X_test)*1.))\n",
    "    t0 = time()\n",
    "    class_fit = pipeline.fit(X_train, y_train)\n",
    "    y_pred = class_fit.predict(X_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"null accuracy: {0:.2f}%\".format(null_accuracy*100))\n",
    "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    if accuracy > null_accuracy:\n",
    "        print(\"model is {0:.2f}% more accurate than null accuracy\".format(\n",
    "            (accuracy-null_accuracy)*100))\n",
    "    elif accuracy == null_accuracy:\n",
    "        print(\"model has the same accuracy with the null accuracy\")\n",
    "    else:\n",
    "        print(\"model is {0:.2f}% less accurate than null accuracy\".format(\n",
    "            (null_accuracy-accuracy)*100))\n",
    "    print(\"train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print(\"-\"*80)\n",
    "    return accuracy, train_test_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "# lr = LogisticRegression()\n",
    "# nb = MultinomialNB()\n",
    "lsvm = SGDClassifier()\n",
    "# 10.000 features:\n",
    "n_features = np.arange(1000, 10001, 1000)\n",
    "\n",
    "\n",
    "def nfeature_accuracy_checker(vectorizer=cvec, n_features=n_features, ngram_range=(1, 1), classifier=lsvm):\n",
    "    result = []\n",
    "    print(classifier)\n",
    "    print(\"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(max_features=n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        print(\"Validation result for {} features\".format(n))\n",
    "        nfeature_accuracy, tt_time = accuracy_summary(\n",
    "            checker_pipeline, X_train, y_train, X_val, y_val)\n",
    "        result.append((n, nfeature_accuracy, tt_time))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfIdfVectorizer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "# # remember to use the original X_train set\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = tvec.fit_transform(X_train)\n",
    "X_train_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "print(\"RESULT FOR BIGRAM WITH STOP WORDS (Tfidf)\\n\")\n",
    "feature_result_tgt = nfeature_accuracy_checker(\n",
    "    vectorizer=tvec, ngram_range=(1, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi2 Feature Selection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "\n",
    "x_train_tfidf = tvec.fit_transform(X_train)\n",
    "\n",
    "\n",
    "x_validation_tfidf = tvec.transform(X_val)\n",
    "\n",
    "chi2score = chi2(x_train_tfidf, y_train)[0]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "wscores = zip(tvec.get_feature_names_out(), chi2score)\n",
    "wchi2 = sorted(wscores, key=lambda x: x[1])\n",
    "topchi2 = list(zip(*wchi2[-20:]))\n",
    "x = range(len(topchi2[1]))\n",
    "labels = topchi2[0]\n",
    "plt.barh(x, topchi2[1], align='center', alpha=0.2)\n",
    "plt.plot(topchi2[1], x, '-o', markersize=5, alpha=0.8)\n",
    "plt.yticks(x, labels)\n",
    "plt.xlabel('$\\chi^2$')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2_result = []\n",
    "for n in np.arange(1000, 10001, 1000):\n",
    "    ch2 = SelectKBest(chi2, k=n)\n",
    "    x_train_chi2_selected = ch2.fit_transform(x_train_tfidf, y_train)\n",
    "    x_validation_chi2_selected = ch2.transform(x_validation_tfidf)\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(x_train_chi2_selected, y_train)\n",
    "    score = clf.score(x_validation_chi2_selected, y_val)\n",
    "    ch2_result.append(score)\n",
    "    print(\"chi2 feature selection evaluation calculated for {} features\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeatures_plot_tgt = pd.DataFrame(feature_result_tgt, columns=[\n",
    "                                  'nfeatures', 'validation_accuracy', 'train_test_time'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(nfeatures_plot_tgt.nfeatures, nfeatures_plot_tgt.validation_accuracy,\n",
    "         label='bigram tfidf vectorizer', color='royalblue')\n",
    "plt.plot(np.arange(1000, 10001, 1000), ch2_result,\n",
    "         label='tfidf dimesions reduced to 10,000 features', linestyle=':', color='orangered')\n",
    "# features limited within tfidft vectorizer and dimensions reduced with chi2\n",
    "plt.title(\"tfidft vectorizer VS reduced dimensions with chi2\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Validation set accuracy\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nfeatures_plot_tgt.head()\n",
    "\n",
    "# print(feature_result_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_N_grams(text, ngram=1):\n",
    "    \"\"\"\"custom function to generate n-grams\"\"\"\n",
    "    words = [word for word in text.split(\n",
    "        \" \") if word not in set(STOPWORDS_GREEK)]\n",
    "    # print(\"Sentence after removing stopwords:\", words)\n",
    "    temp = zip(*[words[i:] for i in range(0, ngram)])\n",
    "    ans = [' '.join(ngram) for ngram in temp]\n",
    "    return ans\n",
    "\n",
    "\n",
    "feminicide_values = defaultdict(int)\n",
    "homicide_values = defaultdict(int)\n",
    "\n",
    "\n",
    "# Get the count of every bigram in the columns of train data set where label=\"Γυναικοκτονία\"\n",
    "for text in df_train[df_train.label == \"Γυναικοκτονία\"].text:\n",
    "    for word in generate_N_grams(text, 2):\n",
    "        feminicide_values[word] += 1\n",
    "\n",
    "# Get the count of every bigram in the columns of train data set where label=\"Ανθρωποκτονία\"\n",
    "for text in df_train[df_train.label == \"Ανθρωποκτονία\"].text:\n",
    "    for word in generate_N_grams(text, 2):\n",
    "        homicide_values[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on more frequently occuring words for every label=>\n",
    "# sort in Descending Order with respect to the 2nd column in each of feminicide_values and homicide_values\n",
    "df_feminicide = pd.DataFrame(\n",
    "    sorted(feminicide_values.items(), key=lambda x: x[1], reverse=True))\n",
    "df_homicide = pd.DataFrame(\n",
    "    sorted(homicide_values.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# ten first values of first column\n",
    "fc1 = df_feminicide[0][:10]\n",
    "# ten first values of second column\n",
    "fc2 = df_feminicide[1][:10]\n",
    "\n",
    "# ten first values of first column\n",
    "hc1 = df_homicide[0][:10]\n",
    "# ten first values of second column\n",
    "hc2 = df_homicide[1][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(16, 4))\n",
    "plt.bar(fc1, fc2, color='purple',\n",
    "        width=0.4)\n",
    "plt.xlabel(\"Words in feminicide dataframe\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in feminicide dataframe-BIGRAM ANALYSIS\")\n",
    "# plt.savefig(\"feminicide-bigram.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(16, 4))\n",
    "plt.bar(hc1, hc2, color='green',\n",
    "        width=0.4)\n",
    "plt.xlabel(\"Words in homicide dataframe\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in homicide dataframe-BIGRAM ANALYSIS\")\n",
    "# plt.savefig(\"homicide-bigram.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
